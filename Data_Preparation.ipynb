{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./FIDs-features/\"\n",
    "\n",
    "def process(df, rType):\n",
    "    df['FID'] = df['p1'].str[:5]\n",
    "    df['p1'] = path+df['p1']\n",
    "    df['p2'] = path+df['p2']\n",
    "    df['p1'] = df['p1'].str.replace('.jpg', '.pkl')\n",
    "    df['p2'] = df['p2'].str.replace('.jpg', '.pkl')\n",
    "    \n",
    "    sample1 = df.sample(n=df.shape[0], replace=True)[['p1','FID']].reset_index().drop('index',axis=1)\n",
    "    sample2 = df.sample(n=df.shape[0], replace=True)[['p2','FID']].reset_index().drop('index',axis=1)\n",
    "    sample2.columns = ['p2','FID2']\n",
    "    unrelated = pd.concat([sample1,sample2],axis=1)\n",
    "    unrelated = unrelated[unrelated['FID'] != unrelated['FID2']][['p1','p2']]\n",
    "    \n",
    "    ###############################################################\n",
    "    # Related file\n",
    "    p1 = df['p1'].values.tolist()\n",
    "    p2 = df['p2'].values.tolist()\n",
    "    F = pd.read_pickle(p1[0]).reshape(1,512)\n",
    "    C = pd.read_pickle(p2[0]).reshape(1,512)\n",
    "    related_fs_set = np.append(F,C,axis=1)\n",
    "\n",
    "    for r1, r2 in zip(p1[1:],p2[1:]):\n",
    "        F = pd.read_pickle(r1).reshape(1,512)\n",
    "        C = pd.read_pickle(r2).reshape(1,512)\n",
    "        temp = np.append(F,C,axis=1)\n",
    "        related_fs_set = np.append(related_fs_set, temp, axis=0)\n",
    "        \n",
    "    pd.DataFrame(related_fs_set).to_pickle(\"Related_{}_1024.pkl\".format(rType))\n",
    "        \n",
    "    ###############################################################\n",
    "    # UnRelated file\n",
    "    p1 = unrelated['p1'].values.tolist()\n",
    "    p2 = unrelated['p2'].values.tolist()\n",
    "    F = pd.read_pickle(p1[0]).reshape(1,512)\n",
    "    C = pd.read_pickle(p2[0]).reshape(1,512)\n",
    "    unrelated_fs_set = np.append(F,C,axis=1)\n",
    "\n",
    "    for r1, r2 in zip(p1[1:],p2[1:]):\n",
    "        F = pd.read_pickle(r1).reshape(1,512)\n",
    "        C = pd.read_pickle(r2).reshape(1,512)\n",
    "        temp = np.append(F,C,axis=1)\n",
    "        unrelated_fs_set = np.append(unrelated_fs_set, temp, axis=0)\n",
    "        \n",
    "    pd.DataFrame(unrelated_fs_set).to_pickle(\"Unrelated_{}_1024.pkl\".format(rType))\n",
    "  \n",
    "# Example \n",
    "process(pd.read_pickle(\"./lists/pairs/pickles/Direct/fs-faces.pkl\"), \"fs\")\n",
    "process(pd.read_pickle(\"./lists/pairs/pickles/Direct/fd-faces.pkl\"), \"fd\")\n",
    "process(pd.read_pickle(\"./lists/pairs/pickles/Direct/ms-faces.pkl\"), \"ms\")\n",
    "process(pd.read_pickle(\"./lists/pairs/pickles/Direct/md-faces.pkl\"), \"md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pd.read_pickle(\"./Related_fs_1024.pkl\")\n",
    "p1['class'] = 1\n",
    "p2 = pd.read_pickle(\"./Unrelated_fs_1024.pkl\")\n",
    "p2['class'] = 0\n",
    "df_fs = pd.concat([p1, p2])\n",
    "df_fs['label'] = 'fs'\n",
    "#################################################################\n",
    "\n",
    "p1 = pd.read_pickle(\"./Related_fd.pkl\")\n",
    "p1['class'] = 1\n",
    "p2 = pd.read_pickle(\"./Unrelated_fd.pkl\")\n",
    "p2['class'] = 0\n",
    "df_fd = pd.concat([p1, p2])\n",
    "df_fd['label'] = 'fd'\n",
    "#################################################################\n",
    "\n",
    "p1 = pd.read_pickle(\"./Related_ms.pkl\")\n",
    "p1['class'] = 1\n",
    "p2 = pd.read_pickle(\"./Unrelated_ms.pkl\")\n",
    "p2['class'] = 0\n",
    "df_ms = pd.concat([p1, p2])\n",
    "df_ms['label'] = 'ms'\n",
    "\n",
    "#################################################################\n",
    "p1 = pd.read_pickle(\"./Related_md.pkl\")\n",
    "p1['class'] = 1\n",
    "p2 = pd.read_pickle(\"./Unrelated_md.pkl\")\n",
    "p2['class'] = 0\n",
    "df_md = pd.concat([p1, p2])\n",
    "df_md['label'] = 'md'\n",
    "\n",
    "\n",
    "df = pd.concat([df_fs, df_fd, df_ms, df_md])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054371</td>\n",
       "      <td>-0.014020</td>\n",
       "      <td>-0.040592</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>-0.005127</td>\n",
       "      <td>-0.032224</td>\n",
       "      <td>0.036430</td>\n",
       "      <td>-0.002104</td>\n",
       "      <td>-0.015939</td>\n",
       "      <td>-0.075741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024401</td>\n",
       "      <td>0.028892</td>\n",
       "      <td>-0.025882</td>\n",
       "      <td>-0.001901</td>\n",
       "      <td>-0.046780</td>\n",
       "      <td>0.042080</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.019761</td>\n",
       "      <td>1</td>\n",
       "      <td>fs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042371</td>\n",
       "      <td>0.035194</td>\n",
       "      <td>0.034465</td>\n",
       "      <td>-0.014003</td>\n",
       "      <td>0.058805</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>-0.033169</td>\n",
       "      <td>-0.053590</td>\n",
       "      <td>-0.010134</td>\n",
       "      <td>0.074855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064253</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>-0.060588</td>\n",
       "      <td>-0.049711</td>\n",
       "      <td>0.077463</td>\n",
       "      <td>0.082833</td>\n",
       "      <td>-0.025950</td>\n",
       "      <td>-0.009140</td>\n",
       "      <td>1</td>\n",
       "      <td>fs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020210</td>\n",
       "      <td>-0.008038</td>\n",
       "      <td>-0.020024</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>-0.061824</td>\n",
       "      <td>-0.019616</td>\n",
       "      <td>0.067781</td>\n",
       "      <td>0.007606</td>\n",
       "      <td>-0.004513</td>\n",
       "      <td>-0.060691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015091</td>\n",
       "      <td>0.022699</td>\n",
       "      <td>-0.129402</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>-0.032020</td>\n",
       "      <td>0.062286</td>\n",
       "      <td>0</td>\n",
       "      <td>fs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010921</td>\n",
       "      <td>0.045188</td>\n",
       "      <td>-0.015183</td>\n",
       "      <td>0.029990</td>\n",
       "      <td>-0.030451</td>\n",
       "      <td>-0.062793</td>\n",
       "      <td>-0.023287</td>\n",
       "      <td>0.041561</td>\n",
       "      <td>0.071418</td>\n",
       "      <td>-0.038416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>-0.014511</td>\n",
       "      <td>0.134132</td>\n",
       "      <td>0.078374</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.043978</td>\n",
       "      <td>-0.050253</td>\n",
       "      <td>0</td>\n",
       "      <td>fs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090976</td>\n",
       "      <td>-0.022020</td>\n",
       "      <td>0.053715</td>\n",
       "      <td>-0.052504</td>\n",
       "      <td>-0.007729</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.014140</td>\n",
       "      <td>-0.024895</td>\n",
       "      <td>0.017223</td>\n",
       "      <td>0.031572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050355</td>\n",
       "      <td>-0.062818</td>\n",
       "      <td>-0.094613</td>\n",
       "      <td>0.015777</td>\n",
       "      <td>0.023049</td>\n",
       "      <td>-0.018808</td>\n",
       "      <td>0.099998</td>\n",
       "      <td>-0.003690</td>\n",
       "      <td>0</td>\n",
       "      <td>fs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.054371 -0.014020 -0.040592  0.001152 -0.005127 -0.032224  0.036430   \n",
       "1  0.042371  0.035194  0.034465 -0.014003  0.058805  0.022217 -0.033169   \n",
       "2  0.020210 -0.008038 -0.020024  0.001893 -0.061824 -0.019616  0.067781   \n",
       "3  0.010921  0.045188 -0.015183  0.029990 -0.030451 -0.062793 -0.023287   \n",
       "4  0.090976 -0.022020  0.053715 -0.052504 -0.007729  0.001302  0.014140   \n",
       "\n",
       "          7         8         9  ...      1016      1017      1018      1019  \\\n",
       "0 -0.002104 -0.015939 -0.075741  ...  0.024401  0.028892 -0.025882 -0.001901   \n",
       "1 -0.053590 -0.010134  0.074855  ...  0.064253  0.025173 -0.060588 -0.049711   \n",
       "2  0.007606 -0.004513 -0.060691  ...  0.015091  0.022699 -0.129402  0.000146   \n",
       "3  0.041561  0.071418 -0.038416  ...  0.037846 -0.014511  0.134132  0.078374   \n",
       "4 -0.024895  0.017223  0.031572  ...  0.050355 -0.062818 -0.094613  0.015777   \n",
       "\n",
       "       1020      1021      1022      1023  class  label  \n",
       "0 -0.046780  0.042080  0.002879  0.019761      1     fs  \n",
       "1  0.077463  0.082833 -0.025950 -0.009140      1     fs  \n",
       "2  0.004989  0.022917 -0.032020  0.062286      0     fs  \n",
       "3  0.013405  0.001500  0.043978 -0.050253      0     fs  \n",
       "4  0.023049 -0.018808  0.099998 -0.003690      0     fs  \n",
       "\n",
       "[5 rows x 1026 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91159, 1026)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(['label','class'],axis=1)[0:50000].values.astype(np.float64)\n",
    "X_valid = df.drop(['label','class'],axis=1)[50000:70000].values.astype(np.float64)\n",
    "X_test = df.drop(['label','class'],axis=1)[70000:].values.astype(np.float64)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = df['class'][0:50000].values.astype(np.int64)\n",
    "y_valid = df['class'][50000:70000].values.astype(np.int64)\n",
    "y_test = df['class'][70000:].values.astype(np.int64)\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train).type(torch.FloatTensor), torch.from_numpy(y_train))\n",
    "valid_dataset = TensorDataset(torch.from_numpy(X_valid).type(torch.FloatTensor), torch.from_numpy(y_valid))\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test).type(torch.FloatTensor), torch.from_numpy(y_test))\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "loaders['valid'] = DataLoader(valid_dataset, batch_size=200)\n",
    "loaders['test'] = DataLoader(test_dataset, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.logSoftMax = nn.LogSoftmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        x = self.dropout(self.relu(self.fc3(x)))\n",
    "        x = self.logSoftMax(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 0.695210 \tValidation Loss: 0.692871\n",
      "Validation loss decreased (inf --> 0.692871).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.692205 \tValidation Loss: 0.691015\n",
      "Validation loss decreased (0.691256 --> 0.691015).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.686702 \tValidation Loss: 0.683937\n",
      "Validation loss decreased (0.685431 --> 0.683937).  Saving model ...\n",
      "Epoch: 30 \tTraining Loss: 0.659876 \tValidation Loss: 0.642457\n",
      "Validation loss decreased (0.651474 --> 0.642457).  Saving model ...\n",
      "Epoch: 40 \tTraining Loss: 0.548252 \tValidation Loss: 0.487112\n",
      "Validation loss decreased (0.503515 --> 0.487112).  Saving model ...\n",
      "Epoch: 50 \tTraining Loss: 0.435167 \tValidation Loss: 0.365942\n",
      "Validation loss decreased (0.372897 --> 0.365942).  Saving model ...\n",
      "Epoch: 60 \tTraining Loss: 0.349718 \tValidation Loss: 0.288616\n",
      "Validation loss decreased (0.295855 --> 0.288616).  Saving model ...\n",
      "Epoch: 70 \tTraining Loss: 0.295995 \tValidation Loss: 0.247370\n",
      "Validation loss decreased (0.249353 --> 0.247370).  Saving model ...\n",
      "Epoch: 80 \tTraining Loss: 0.253949 \tValidation Loss: 0.217584\n",
      "Validation loss decreased (0.220859 --> 0.217584).  Saving model ...\n",
      "Epoch: 90 \tTraining Loss: 0.224033 \tValidation Loss: 0.199353\n",
      "Epoch: 100 \tTraining Loss: 0.199160 \tValidation Loss: 0.185155\n",
      "Validation loss decreased (0.186843 --> 0.185155).  Saving model ...\n",
      "Epoch: 110 \tTraining Loss: 0.179056 \tValidation Loss: 0.173746\n",
      "Validation loss decreased (0.175109 --> 0.173746).  Saving model ...\n",
      "Epoch: 120 \tTraining Loss: 0.164068 \tValidation Loss: 0.166611\n",
      "Validation loss decreased (0.167706 --> 0.166611).  Saving model ...\n",
      "Epoch: 130 \tTraining Loss: 0.151024 \tValidation Loss: 0.160593\n",
      "Validation loss decreased (0.161140 --> 0.160593).  Saving model ...\n",
      "Epoch: 140 \tTraining Loss: 0.132299 \tValidation Loss: 0.154119\n",
      "Validation loss decreased (0.156738 --> 0.154119).  Saving model ...\n",
      "Epoch: 150 \tTraining Loss: 0.127064 \tValidation Loss: 0.151826\n",
      "Validation loss decreased (0.152415 --> 0.151826).  Saving model ...\n",
      "Epoch: 160 \tTraining Loss: 0.113237 \tValidation Loss: 0.147141\n",
      "Validation loss decreased (0.149859 --> 0.147141).  Saving model ...\n",
      "Epoch: 170 \tTraining Loss: 0.109207 \tValidation Loss: 0.147198\n",
      "Epoch: 180 \tTraining Loss: 0.102517 \tValidation Loss: 0.146286\n",
      "Epoch: 190 \tTraining Loss: 0.090452 \tValidation Loss: 0.143304\n",
      "Validation loss decreased (0.143814 --> 0.143304).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"returns trained model\"\"\"\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf \n",
    "\n",
    "for epoch in range(200):\n",
    "    # initialize variables to monitor training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        optimizer.zero_grad()\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        ## find the loss and update the model parameters accordingly\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ## record the average training loss, using something like\n",
    "        train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "\n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        ## update the average validation loss\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, target)\n",
    "        valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "    if(epoch % 10 == 0):\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "\n",
    "    ## TODO: save the model if validation loss has decreased\n",
    "    if valid_loss < valid_loss_min:\n",
    "        if(epoch % 10 == 0):\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), \"checkpoint.cpt\")\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.146854\n",
      "\n",
      "\n",
      "Test Accuracy: 94% (20006/21159)\n"
     ]
    }
   ],
   "source": [
    "# monitor test loss and accuracy\n",
    "test_loss = 0.\n",
    "correct = 0.\n",
    "total = 0.\n",
    "\n",
    "model.eval()\n",
    "for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "    # move to GPU\n",
    "    if use_cuda:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update average test loss \n",
    "    test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "    # convert output probabilities to predicted class\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    # compare predictions to true label\n",
    "    correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "    total += data.size(0)\n",
    "\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "    100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
