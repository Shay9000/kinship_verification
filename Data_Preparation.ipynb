{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./FIDs-features/\"\n",
    "\n",
    "def process(df, rType):\n",
    "    df['FID'] = df['p1'].str[:5]\n",
    "    df['p1'] = path+df['p1']\n",
    "    df['p2'] = path+df['p2']\n",
    "    df['p1'] = df['p1'].str.replace('.jpg', '.pkl')\n",
    "    df['p2'] = df['p2'].str.replace('.jpg', '.pkl')\n",
    "    \n",
    "    sample1 = df.sample(n=df.shape[0], replace=True)[['p1','FID']].reset_index().drop('index',axis=1)\n",
    "    sample2 = df.sample(n=df.shape[0], replace=True)[['p2','FID']].reset_index().drop('index',axis=1)\n",
    "    sample2.columns = ['p2','FID2']\n",
    "    unrelated = pd.concat([sample1,sample2],axis=1)\n",
    "    unrelated = unrelated[unrelated['FID'] != unrelated['FID2']][['p1','p2']]\n",
    "    \n",
    "    ###############################################################\n",
    "    # Related file\n",
    "    p1 = df['p1'].values.tolist()\n",
    "    p2 = df['p2'].values.tolist()\n",
    "    F = pd.read_pickle(p1[0]).reshape(1,512)\n",
    "    C = pd.read_pickle(p2[0]).reshape(1,512)\n",
    "    related_fs_set = np.append(F,C,axis=1)\n",
    "\n",
    "    for r1, r2 in zip(p1[1:],p2[1:]):\n",
    "        F = pd.read_pickle(r1).reshape(1,512)\n",
    "        C = pd.read_pickle(r2).reshape(1,512)\n",
    "        temp = np.append(F,C,axis=1)\n",
    "        related_fs_set = np.append(related_fs_set, temp, axis=0)\n",
    "        \n",
    "    pd.DataFrame(related_fs_set).to_pickle(\"Related_{}_1024.pkl\".format(rType))\n",
    "        \n",
    "    ###############################################################\n",
    "    # UnRelated file\n",
    "    p1 = unrelated['p1'].values.tolist()\n",
    "    p2 = unrelated['p2'].values.tolist()\n",
    "    F = pd.read_pickle(p1[0]).reshape(1,512)\n",
    "    C = pd.read_pickle(p2[0]).reshape(1,512)\n",
    "    unrelated_fs_set = np.append(F,C,axis=1)\n",
    "\n",
    "    for r1, r2 in zip(p1[1:],p2[1:]):\n",
    "        F = pd.read_pickle(r1).reshape(1,512)\n",
    "        C = pd.read_pickle(r2).reshape(1,512)\n",
    "        temp = np.append(F,C,axis=1)\n",
    "        unrelated_fs_set = np.append(unrelated_fs_set, temp, axis=0)\n",
    "        \n",
    "    pd.DataFrame(unrelated_fs_set).to_pickle(\"Unrelated_{}_1024.pkl\".format(rType))\n",
    "  \n",
    "# Example \n",
    "process(pd.read_pickle(\"./lists/pairs/pickles/Direct/fs-faces.pkl\"), \"fs\")\n",
    "process(pd.read_pickle(\"./lists/pairs/pickles/Direct/fd-faces.pkl\"), \"fd\")\n",
    "process(pd.read_pickle(\"./lists/pairs/pickles/Direct/ms-faces.pkl\"), \"ms\")\n",
    "process(pd.read_pickle(\"./lists/pairs/pickles/Direct/md-faces.pkl\"), \"md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pd.read_pickle(\"./Related_fs_1024.pkl\")\n",
    "p1['class'] = 1\n",
    "p2 = pd.read_pickle(\"./Unrelated_fs_1024.pkl\")\n",
    "p2['class'] = 0\n",
    "df_fs = pd.concat([p1, p2])\n",
    "df_fs['label'] = 'fs'\n",
    "#################################################################\n",
    "\n",
    "p1 = pd.read_pickle(\"./Related_fd_1024.pkl\")\n",
    "p1['class'] = 1\n",
    "p2 = pd.read_pickle(\"./Unrelated_fd_1024.pkl\")\n",
    "p2['class'] = 0\n",
    "df_fd = pd.concat([p1, p2])\n",
    "df_fd['label'] = 'fd'\n",
    "#################################################################\n",
    "\n",
    "p1 = pd.read_pickle(\"./Related_ms_1024.pkl\")\n",
    "p1['class'] = 1\n",
    "p2 = pd.read_pickle(\"./Unrelated_ms_1024.pkl\")\n",
    "p2['class'] = 0\n",
    "df_ms = pd.concat([p1, p2])\n",
    "df_ms['label'] = 'ms'\n",
    "\n",
    "#################################################################\n",
    "p1 = pd.read_pickle(\"./Related_md_1024.pkl\")\n",
    "p1['class'] = 1\n",
    "p2 = pd.read_pickle(\"./Unrelated_md_1024.pkl\")\n",
    "p2['class'] = 0\n",
    "df_md = pd.concat([p1, p2])\n",
    "df_md['label'] = 'md'\n",
    "\n",
    "\n",
    "df = pd.concat([df_fs, df_fd, df_ms, df_md])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.032823</td>\n",
       "      <td>0.016928</td>\n",
       "      <td>0.038539</td>\n",
       "      <td>-0.042057</td>\n",
       "      <td>0.029449</td>\n",
       "      <td>-0.044304</td>\n",
       "      <td>-0.040221</td>\n",
       "      <td>0.054967</td>\n",
       "      <td>0.075987</td>\n",
       "      <td>-0.058166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092484</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>0.019293</td>\n",
       "      <td>0.019862</td>\n",
       "      <td>-0.075243</td>\n",
       "      <td>-0.030094</td>\n",
       "      <td>0.037646</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>1</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.051185</td>\n",
       "      <td>-0.057742</td>\n",
       "      <td>0.039662</td>\n",
       "      <td>-0.018204</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>0.032607</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>-0.014386</td>\n",
       "      <td>0.071762</td>\n",
       "      <td>0.052504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038251</td>\n",
       "      <td>-0.025545</td>\n",
       "      <td>-0.078499</td>\n",
       "      <td>0.073234</td>\n",
       "      <td>-0.058362</td>\n",
       "      <td>-0.045331</td>\n",
       "      <td>0.037149</td>\n",
       "      <td>-0.000495</td>\n",
       "      <td>1</td>\n",
       "      <td>fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.028367</td>\n",
       "      <td>-0.033695</td>\n",
       "      <td>-0.003411</td>\n",
       "      <td>-0.026240</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>-0.076316</td>\n",
       "      <td>0.094834</td>\n",
       "      <td>-0.061823</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.061454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.018681</td>\n",
       "      <td>-0.013638</td>\n",
       "      <td>0.028098</td>\n",
       "      <td>0.072126</td>\n",
       "      <td>-0.014650</td>\n",
       "      <td>-0.025738</td>\n",
       "      <td>-0.036153</td>\n",
       "      <td>0</td>\n",
       "      <td>ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.021218</td>\n",
       "      <td>0.014343</td>\n",
       "      <td>0.130578</td>\n",
       "      <td>0.006806</td>\n",
       "      <td>0.041132</td>\n",
       "      <td>-0.043561</td>\n",
       "      <td>-0.034983</td>\n",
       "      <td>0.026983</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>0.120143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006648</td>\n",
       "      <td>0.041588</td>\n",
       "      <td>-0.041931</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.017354</td>\n",
       "      <td>-0.067018</td>\n",
       "      <td>0.038646</td>\n",
       "      <td>0.028507</td>\n",
       "      <td>1</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047261</td>\n",
       "      <td>0.012104</td>\n",
       "      <td>0.119618</td>\n",
       "      <td>0.036309</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>-0.090445</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.033187</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012846</td>\n",
       "      <td>-0.002183</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>-0.025867</td>\n",
       "      <td>-0.011832</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>-0.057677</td>\n",
       "      <td>-0.052642</td>\n",
       "      <td>1</td>\n",
       "      <td>fs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.032823  0.016928  0.038539 -0.042057  0.029449 -0.044304 -0.040221   \n",
       "1 -0.051185 -0.057742  0.039662 -0.018204  0.015373  0.032607  0.001345   \n",
       "2 -0.028367 -0.033695 -0.003411 -0.026240 -0.000167 -0.076316  0.094834   \n",
       "3 -0.021218  0.014343  0.130578  0.006806  0.041132 -0.043561 -0.034983   \n",
       "4  0.047261  0.012104  0.119618  0.036309  0.013233 -0.090445  0.003090   \n",
       "\n",
       "          7         8         9  ...      1016      1017      1018      1019  \\\n",
       "0  0.054967  0.075987 -0.058166  ...  0.092484 -0.001384  0.019293  0.019862   \n",
       "1 -0.014386  0.071762  0.052504  ... -0.038251 -0.025545 -0.078499  0.073234   \n",
       "2 -0.061823  0.015014  0.061454  ...  0.001499  0.018681 -0.013638  0.028098   \n",
       "3  0.026983  0.016530  0.120143  ... -0.006648  0.041588 -0.041931  0.004982   \n",
       "4  0.003694  0.033187 -0.005173  ...  0.012846 -0.002183  0.032308 -0.025867   \n",
       "\n",
       "       1020      1021      1022      1023  class  label  \n",
       "0 -0.075243 -0.030094  0.037646 -0.000995      1     md  \n",
       "1 -0.058362 -0.045331  0.037149 -0.000495      1     fd  \n",
       "2  0.072126 -0.014650 -0.025738 -0.036153      0     ms  \n",
       "3  0.017354 -0.067018  0.038646  0.028507      1     md  \n",
       "4 -0.011832  0.007127 -0.057677 -0.052642      1     fs  \n",
       "\n",
       "[5 rows x 1026 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(['label','class'],axis=1)[0:300000].values.astype(np.float64)\n",
    "X_valid = df.drop(['label','class'],axis=1)[300000:370000].values.astype(np.float64)\n",
    "X_test = df.drop(['label','class'],axis=1)[370000:].values.astype(np.float64)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = df['class'][0:300000].values.astype(np.int64)\n",
    "y_valid = df['class'][300000:370000].values.astype(np.int64)\n",
    "y_test = df['class'][370000:].values.astype(np.int64)\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train).type(torch.FloatTensor), torch.from_numpy(y_train))\n",
    "valid_dataset = TensorDataset(torch.from_numpy(X_valid).type(torch.FloatTensor), torch.from_numpy(y_valid))\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test).type(torch.FloatTensor), torch.from_numpy(y_test))\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "loaders['valid'] = DataLoader(valid_dataset, batch_size=200)\n",
    "loaders['test'] = DataLoader(test_dataset, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.logSoftMax = nn.LogSoftmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        x = self.dropout(self.relu(self.fc3(x)))\n",
    "        x = self.logSoftMax(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 0.693051 \tValidation Loss: 0.690293\n",
      "Validation loss decreased (inf --> 0.690293).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.545161 \tValidation Loss: 0.511763\n",
      "Validation loss decreased (0.524733 --> 0.511763).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.417602 \tValidation Loss: 0.364236\n",
      "Validation loss decreased (0.378216 --> 0.364236).  Saving model ...\n",
      "Epoch: 30 \tTraining Loss: 0.336811 \tValidation Loss: 0.282483\n",
      "Validation loss decreased (0.284864 --> 0.282483).  Saving model ...\n",
      "Epoch: 40 \tTraining Loss: 0.288169 \tValidation Loss: 0.239538\n",
      "Validation loss decreased (0.244177 --> 0.239538).  Saving model ...\n",
      "Epoch: 50 \tTraining Loss: 0.257086 \tValidation Loss: 0.211998\n",
      "Validation loss decreased (0.214534 --> 0.211998).  Saving model ...\n",
      "Epoch: 60 \tTraining Loss: 0.229341 \tValidation Loss: 0.193628\n",
      "Validation loss decreased (0.195296 --> 0.193628).  Saving model ...\n",
      "Epoch: 70 \tTraining Loss: 0.210941 \tValidation Loss: 0.177830\n",
      "Validation loss decreased (0.181825 --> 0.177830).  Saving model ...\n",
      "Epoch: 80 \tTraining Loss: 0.195424 \tValidation Loss: 0.169405\n",
      "Validation loss decreased (0.170806 --> 0.169405).  Saving model ...\n",
      "Epoch: 90 \tTraining Loss: 0.182550 \tValidation Loss: 0.160238\n",
      "Validation loss decreased (0.160844 --> 0.160238).  Saving model ...\n",
      "Epoch: 100 \tTraining Loss: 0.169911 \tValidation Loss: 0.154522\n",
      "Epoch: 110 \tTraining Loss: 0.163460 \tValidation Loss: 0.148364\n",
      "Epoch: 120 \tTraining Loss: 0.153396 \tValidation Loss: 0.144397\n",
      "Epoch: 130 \tTraining Loss: 0.146639 \tValidation Loss: 0.138224\n",
      "Epoch: 140 \tTraining Loss: 0.141184 \tValidation Loss: 0.136388\n",
      "Epoch: 150 \tTraining Loss: 0.135173 \tValidation Loss: 0.132692\n",
      "Epoch: 160 \tTraining Loss: 0.131741 \tValidation Loss: 0.129894\n",
      "Validation loss decreased (0.130217 --> 0.129894).  Saving model ...\n",
      "Epoch: 170 \tTraining Loss: 0.127064 \tValidation Loss: 0.127662\n",
      "Epoch: 180 \tTraining Loss: 0.123835 \tValidation Loss: 0.126851\n",
      "Epoch: 190 \tTraining Loss: 0.120307 \tValidation Loss: 0.125174\n"
     ]
    }
   ],
   "source": [
    "\"\"\"returns trained model\"\"\"\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf \n",
    "\n",
    "for epoch in range(200):\n",
    "    # initialize variables to monitor training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        optimizer.zero_grad()\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        ## find the loss and update the model parameters accordingly\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ## record the average training loss, using something like\n",
    "        train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "\n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        ## update the average validation loss\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, target)\n",
    "        valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "    if(epoch % 10 == 0):\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "\n",
    "    ## TODO: save the model if validation loss has decreased\n",
    "    if valid_loss < valid_loss_min:\n",
    "        if(epoch % 10 == 0):\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "        torch.save(model.state_dict(), \"checkpoint.cpt\")\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.124207\n",
      "\n",
      "\n",
      "Test Accuracy: 95% (65273/68579)\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoint.cpt'))\n",
    "# monitor test loss and accuracy\n",
    "test_loss = 0.\n",
    "correct = 0.\n",
    "total = 0.\n",
    "\n",
    "model.eval()\n",
    "for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "    # move to GPU\n",
    "    if use_cuda:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update average test loss \n",
    "    test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "    # convert output probabilities to predicted class\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    # compare predictions to true label\n",
    "    correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "    total += data.size(0)\n",
    "\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "    100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
