{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline                               \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download From https://drive.google.com/file/d/1lcLgDvpj_yRCKsjH-eG6Km46VY3bakys/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"./train_5.pkl\")\n",
    "valid_df = pd.read_pickle(\"./valid_5.pkl\")\n",
    "test_df = pd.read_pickle(\"./test_5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Family DataSet\n",
    "X_train = train_df.drop('label',axis=1).values.astype(np.float64)\n",
    "X_valid = valid_df.drop('label',axis=1).values.astype(np.float64)\n",
    "X_test = test_df.drop('label',axis=1).values.astype(np.float64)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "realation_dict = {'fs':0, 'fd':1, 'ms':2, 'md':3, 'un':4}\n",
    "y_train = train_df['label'].map(realation_dict).values.astype(np.int64)\n",
    "y_valid = valid_df['label'].map(realation_dict).values.astype(np.int64)\n",
    "y_test = test_df['label'].map(realation_dict).values.astype(np.int64)\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train).type(torch.FloatTensor), torch.from_numpy(y_train))\n",
    "valid_dataset = TensorDataset(torch.from_numpy(X_valid).type(torch.FloatTensor), torch.from_numpy(y_valid))\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test).type(torch.FloatTensor), torch.from_numpy(y_test))\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "loaders['valid'] = DataLoader(valid_dataset, batch_size=200)\n",
    "loaders['test'] = DataLoader(test_dataset, batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Family Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.output = nn.Linear(64, 5)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.logSoftMax = nn.LogSoftmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.logSoftMax(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf \n",
    "\n",
    "for epoch in range(400):\n",
    "    # initialize variables to monitor training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        optimizer.zero_grad()\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        ## find the loss and update the model parameters accordingly\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ## record the average training loss, using something like\n",
    "        train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "\n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        ## update the average validation loss\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, target)\n",
    "        valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "    if(epoch % 10 == 0):\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "\n",
    "    ## TODO: save the model if validation loss has decreased\n",
    "    if valid_loss < valid_loss_min:\n",
    "        if(epoch % 10 == 0):\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "        torch.save(model.state_dict(), \"model5_checkpoint.cpt\")\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model5_checkpoint.cpt'))\n",
    "# monitor test loss and accuracy\n",
    "test_loss = 0.\n",
    "correct = 0.\n",
    "total = 0.\n",
    "\n",
    "model.eval()\n",
    "for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "    # move to GPU\n",
    "    if use_cuda:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update average test loss \n",
    "    test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "    # convert output probabilities to predicted class\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    # compare predictions to true label\n",
    "    correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "    total += data.size(0)\n",
    "\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "    100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
